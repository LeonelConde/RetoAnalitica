{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-data-from-tsv-source\" data-toc-modified-id=\"Read-data-from-tsv-source-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Read data from tsv source</a></span></li><li><span><a href=\"#Connect-to-database\" data-toc-modified-id=\"Connect-to-database-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Connect to database</a></span></li><li><span><a href=\"#Save-subreddit-category-info\" data-toc-modified-id=\"Save-subreddit-category-info-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Save subreddit category info</a></span></li><li><span><a href=\"#Cleaning-function\" data-toc-modified-id=\"Cleaning-function-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cleaning function</a></span></li><li><span><a href=\"#Create-new-column-in-dataframe\" data-toc-modified-id=\"Create-new-column-in-dataframe-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create new column in dataframe</a></span></li><li><span><a href=\"#Load-spaCy\" data-toc-modified-id=\"Load-spaCy-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Load spaCy</a></span></li><li><span><a href=\"#Iterate-over-all-rows-and-perform-NLP\" data-toc-modified-id=\"Iterate-over-all-rows-and-perform-NLP-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Iterate over all rows and perform NLP</a></span></li><li><span><a href=\"#Check-results\" data-toc-modified-id=\"Check-results-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Check results</a></span></li><li><span><a href=\"#Save-to-database\" data-toc-modified-id=\"Save-to-database-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Save to database</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from tsv source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:25:50.316246Z",
     "start_time": "2018-12-11T18:25:37.226960Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
       "      <td>astroworld</td>\n",
       "      <td>wednesday addams as a disney princess keepin i...</td>\n",
       "      <td>2017-05-26 05:46:42</td>\n",
       "      <td>624</td>\n",
       "      <td>950</td>\n",
       "      <td>18775</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:21</td>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Basile üá∫üá∏</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n",
       "      <td>2009-04-16 20:06:23</td>\n",
       "      <td>2253</td>\n",
       "      <td>1677</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-25 12:27:17</td>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time4fisticuffs</td>\n",
       "      <td>Pewee Valley, KY</td>\n",
       "      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n",
       "      <td>2009-02-28 18:57:41</td>\n",
       "      <td>9275</td>\n",
       "      <td>9525</td>\n",
       "      <td>7254</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:14</td>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethel mertz</td>\n",
       "      <td>Stuck in the Middle</td>\n",
       "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n",
       "      <td>2019-03-07 01:45:06</td>\n",
       "      <td>197</td>\n",
       "      <td>987</td>\n",
       "      <td>1488</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:10</td>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIPR-J&amp;K</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>üñäÔ∏èOfficial Twitter handle of Department of Inf...</td>\n",
       "      <td>2017-02-12 06:45:15</td>\n",
       "      <td>101009</td>\n",
       "      <td>168</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:08</td>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74431</th>\n",
       "      <td>Laura Wolfrom</td>\n",
       "      <td>Lexington, KY</td>\n",
       "      <td>The only things I collect are memories.</td>\n",
       "      <td>2010-09-24 02:01:15</td>\n",
       "      <td>85</td>\n",
       "      <td>586</td>\n",
       "      <td>1902</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-04 03:13:29</td>\n",
       "      <td>So far this summer I have filled up my lawn mo...</td>\n",
       "      <td>['COVID19', 'QuarantineLife']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74432</th>\n",
       "      <td>Professor Tonya M. Evans</td>\n",
       "      <td>üò∑ #stayathome</td>\n",
       "      <td>Law Prof @DickinsonLaw &amp; Entrepreneur | Crypto...</td>\n",
       "      <td>2013-05-14 20:15:24</td>\n",
       "      <td>4289</td>\n",
       "      <td>1066</td>\n",
       "      <td>53569</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-04 03:13:26</td>\n",
       "      <td>ICYMI: REPLAY: #TechIntersectüß© #16: Isaiah \"@B...</td>\n",
       "      <td>['TechIntersect', 'Bitcoin', 'COVID19']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74433</th>\n",
       "      <td>People's Daily app</td>\n",
       "      <td>Âåó‰∫¨, ‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩ</td>\n",
       "      <td>Our mission is to provide news and perspective...</td>\n",
       "      <td>2018-02-04 12:36:42</td>\n",
       "      <td>1413</td>\n",
       "      <td>102</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-04 03:13:22</td>\n",
       "      <td>Community workers in Tianshan District of Urum...</td>\n",
       "      <td>['China', 'Xinjiang']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74434</th>\n",
       "      <td>M0ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reagan conservative and attorney raised in the...</td>\n",
       "      <td>2014-02-18 03:46:28</td>\n",
       "      <td>2554</td>\n",
       "      <td>1733</td>\n",
       "      <td>129104</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-04 03:13:19</td>\n",
       "      <td>If only we had a responsible media to warn us ...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74435</th>\n",
       "      <td>Your Friend &amp; Sabre ‚öîÔ∏è</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>My spectral decomposition has a significant da...</td>\n",
       "      <td>2016-12-19 19:55:00</td>\n",
       "      <td>310</td>\n",
       "      <td>1748</td>\n",
       "      <td>60133</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-04 03:13:15</td>\n",
       "      <td>MAGA: #COVID19 is just a cold &amp;amp; it'd be go...</td>\n",
       "      <td>['COVID19', 'Hydroxycholoroquine']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74436 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_name         user_location  \\\n",
       "0                        ·èâ·é•‚òª’¨ÍÇÖœÆ            astroworld   \n",
       "1                 Tom Basile üá∫üá∏          New York, NY   \n",
       "2               Time4fisticuffs      Pewee Valley, KY   \n",
       "3                   ethel mertz  Stuck in the Middle    \n",
       "4                      DIPR-J&K     Jammu and Kashmir   \n",
       "...                         ...                   ...   \n",
       "74431             Laura Wolfrom         Lexington, KY   \n",
       "74432  Professor Tonya M. Evans         üò∑ #stayathome   \n",
       "74433        People's Daily app           Âåó‰∫¨, ‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩ   \n",
       "74434                     M0ser                   NaN   \n",
       "74435    Your Friend & Sabre ‚öîÔ∏è           Chicago, IL   \n",
       "\n",
       "                                        user_description         user_created  \\\n",
       "0      wednesday addams as a disney princess keepin i...  2017-05-26 05:46:42   \n",
       "1      Husband, Father, Columnist & Commentator. Auth...  2009-04-16 20:06:23   \n",
       "2      #Christian #Catholic #Conservative #Reagan #Re...  2009-02-28 18:57:41   \n",
       "3      #Browns #Indians #ClevelandProud #[]_[] #Cavs ...  2019-03-07 01:45:06   \n",
       "4      üñäÔ∏èOfficial Twitter handle of Department of Inf...  2017-02-12 06:45:15   \n",
       "...                                                  ...                  ...   \n",
       "74431            The only things I collect are memories.  2010-09-24 02:01:15   \n",
       "74432  Law Prof @DickinsonLaw & Entrepreneur | Crypto...  2013-05-14 20:15:24   \n",
       "74433  Our mission is to provide news and perspective...  2018-02-04 12:36:42   \n",
       "74434  Reagan conservative and attorney raised in the...  2014-02-18 03:46:28   \n",
       "74435  My spectral decomposition has a significant da...  2016-12-19 19:55:00   \n",
       "\n",
       "       user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0                 624           950            18775          False   \n",
       "1                2253          1677               24           True   \n",
       "2                9275          9525             7254          False   \n",
       "3                 197           987             1488          False   \n",
       "4              101009           168              101          False   \n",
       "...               ...           ...              ...            ...   \n",
       "74431              85           586             1902          False   \n",
       "74432            4289          1066            53569          False   \n",
       "74433            1413           102               16          False   \n",
       "74434            2554          1733           129104          False   \n",
       "74435             310          1748            60133          False   \n",
       "\n",
       "                      date                                               text  \\\n",
       "0      2020-07-25 12:27:21  If I smelled the scent of hand sanitizers toda...   \n",
       "1      2020-07-25 12:27:17  Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2      2020-07-25 12:27:14  @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3      2020-07-25 12:27:10  @brookbanktv The one gift #COVID19 has give me...   \n",
       "4      2020-07-25 12:27:08  25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "...                    ...                                                ...   \n",
       "74431  2020-08-04 03:13:29  So far this summer I have filled up my lawn mo...   \n",
       "74432  2020-08-04 03:13:26  ICYMI: REPLAY: #TechIntersectüß© #16: Isaiah \"@B...   \n",
       "74433  2020-08-04 03:13:22  Community workers in Tianshan District of Urum...   \n",
       "74434  2020-08-04 03:13:19  If only we had a responsible media to warn us ...   \n",
       "74435  2020-08-04 03:13:15  MAGA: #COVID19 is just a cold &amp; it'd be go...   \n",
       "\n",
       "                                      hashtags               source  \\\n",
       "0                                          NaN   Twitter for iPhone   \n",
       "1                                          NaN  Twitter for Android   \n",
       "2                                  ['COVID19']  Twitter for Android   \n",
       "3                                  ['COVID19']   Twitter for iPhone   \n",
       "4            ['CoronaVirusUpdates', 'COVID19']  Twitter for Android   \n",
       "...                                        ...                  ...   \n",
       "74431            ['COVID19', 'QuarantineLife']   Twitter for iPhone   \n",
       "74432  ['TechIntersect', 'Bitcoin', 'COVID19']      Twitter Web App   \n",
       "74433                    ['China', 'Xinjiang']      Twitter Web App   \n",
       "74434                              ['COVID19']   Twitter for iPhone   \n",
       "74435       ['COVID19', 'Hydroxycholoroquine']  Twitter for Android   \n",
       "\n",
       "       is_retweet  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "...           ...  \n",
       "74431       False  \n",
       "74432       False  \n",
       "74433       False  \n",
       "74434       False  \n",
       "74435       False  \n",
       "\n",
       "[74436 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect('selfposts.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save subreddit category info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'categories' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5a092839eac9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"covid19_tweets.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"categories\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Ambiente 1\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2603\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2605\u001b[1;33m         sql.to_sql(\n\u001b[0m\u001b[0;32m   2606\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Ambiente 1\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m    587\u001b[0m         )\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m     pandas_sql.to_sql(\n\u001b[0m\u001b[0;32m    590\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Ambiente 1\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   1825\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m         )\n\u001b[1;32m-> 1827\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1828\u001b[0m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Ambiente 1\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fail\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'categories' already exists."
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"covid19_tweets.csv\").to_sql(\"categories\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(s):\n",
    "    s = s.replace(r'<lb>', \"\\n\")\n",
    "    s = s.replace(r'<tab>', \"\\i\")\n",
    "    s = re.sub(r'<br */*>', \"\\n\", s)\n",
    "    s = s.replace(\"&lt;\", \"<\").replace(\"&gt;\", \">\").replace(\"&amp;\", \"&\")\n",
    "    s = s.replace(\"&amp;\", \"&\")\n",
    "    # markdown urls\n",
    "    s = re.sub(r'\\(https*://[^\\)]*\\)', \"\", s)\n",
    "    # normal urls\n",
    "    s = re.sub(r'https*://[^\\s]*', \"\", s)\n",
    "    s = re.sub(r'_+', ' ', s)\n",
    "    s = re.sub(r'\"+', '\"', s)\n",
    "    return str(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"selftext_clean\"] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    df.at[i, \"selftext_clean\"] = clean(row.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over all rows and perform NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    if(row[\"selftext_clean\"] and len(str(row[\"selftext_clean\"])) < 1000000):\n",
    "        doc = nlp(str(row[\"selftext_clean\"]))\n",
    "        adjectives = []\n",
    "        nouns = []\n",
    "        verbs = []\n",
    "        lemmas = []\n",
    "\n",
    "        for token in doc:\n",
    "            lemmas.append(token.lemma_)\n",
    "            if token.pos_ == \"ADJ\":\n",
    "                adjectives.append(token.lemma_)\n",
    "            if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
    "                nouns.append(token.lemma_)\n",
    "            if token.pos_ == \"VERB\":\n",
    "                verbs.append(token.lemma_)\n",
    "                \n",
    "        df.at[i, \"selftext_lemma\"] = \" \".join(lemmas)                \n",
    "        df.at[i, \"selftext_nouns\"] = \" \".join(nouns)\n",
    "        df.at[i, \"selftext_adjectives\"] = \" \".join(adjectives)\n",
    "        df.at[i, \"selftext_verbs\"] = \" \".join(verbs)\n",
    "        df.at[i, \"selftext_nav\"] = \" \".join(nouns+adjectives+verbs)\n",
    "        df.at[i, \"no_tokens\"] = len(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('posts_nlp', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
